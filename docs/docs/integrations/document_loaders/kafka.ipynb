{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KafkaLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import KafkaDocumentLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kafka Producer in Langchain Integration with Kafka\n",
    "In the Langchain integration with Kafka, a Kafka Producer is used to send messages to a Kafka topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message delivered to test_topic_2 [0]\n",
      "Message delivered to test_topic_2 [0]\n",
      "Message delivered to test_topic_2 [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from confluent_kafka import Producer\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Kafka producer configuration\n",
    "bootstrap_servers = 'localhost:9092'\n",
    "topic_name = 'test_topic_2'\n",
    "\n",
    "# Create a Kafka producer instance\n",
    "conf = {'bootstrap.servers': bootstrap_servers}\n",
    "producer = Producer(conf)\n",
    "\n",
    "# Sample documents to send\n",
    "documents = [\n",
    "    {\n",
    "        'content': 'This is the first document.',\n",
    "        'metadata': {'source': 'document1.txt'}\n",
    "    },\n",
    "    {\n",
    "        'content': 'This is the second document.',\n",
    "        'metadata': {'source': 'document2.txt'}\n",
    "    },\n",
    "    {\n",
    "        'content': 'This is the third document.',\n",
    "        'metadata': {'source': 'document3.txt'}\n",
    "    }\n",
    "]\n",
    "\n",
    "# Callback function for delivery reports\n",
    "def delivery_report(err, msg):\n",
    "    if err is not None:\n",
    "        print(f'Message delivery failed: {err}')\n",
    "    else:\n",
    "        print(f'Message delivered to {msg.topic()} [{msg.partition()}]')\n",
    "\n",
    "# Send documents to Kafka\n",
    "for document in documents:\n",
    "    producer.produce(topic_name, json.dumps(document).encode('utf-8'), callback=delivery_report)\n",
    "    producer.poll(0)\n",
    "    time.sleep(1)  # Add a delay between sending messages (optional)\n",
    "\n",
    "# Wait for any outstanding messages to be delivered and delivery reports to be received\n",
    "producer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of Using and Integrating the Open Source Apache Kafka Loader with Langchain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import necessary modules\n",
    "from langchain_core.documents import Document\n",
    "from confluent_kafka import KafkaException, KafkaError\n",
    "from langchain_community.document_loaders.kafka import KafkaDocumentLoader\n",
    "\n",
    "kafka_loader = KafkaDocumentLoader(\n",
    "    bootstrap_servers='localhost:9092',\n",
    "    topic='my-topic',\n",
    "    group_id='my-group',\n",
    "    auto_offset_reset='earliest'\n",
    ")\n",
    "\n",
    "try:\n",
    "    documents = kafka_loader.load()\n",
    "    for doc in documents:\n",
    "        print(doc)\n",
    "except KafkaException as e:\n",
    "    print(f\"Kafka exception occurred: {e}\")\n",
    "finally:\n",
    "    kafka_loader.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of Using and Integrating the Apache Kafka Loader with Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders.kafka import KafkaDocumentLoader\n",
    "\n",
    "# Initialize KafkaDocumentLoader\n",
    "kafka_loader = KafkaDocumentLoader(\n",
    "    bootstrap_servers='localhost:9092',\n",
    "    topic='test_topic_2',\n",
    "    group_id='test_group',\n",
    "    auto_offset_reset='earliest'\n",
    ")\n",
    "\n",
    "# Load documents\n",
    "documents = kafka_loader.load()\n",
    "\n",
    "for i, doc in enumerate(documents, start=1):\n",
    "    print(f\"Document {i}:\")\n",
    "    print(doc)\n",
    "    print(\"---\")\n",
    "\n",
    "# Close the loader\n",
    "kafka_loader.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of Using and Integrating the Confluent Platform with Langchain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.kafka import KafkaDocumentLoader\n",
    "\n",
    "# Confluent Platform\n",
    "kafka_loader = KafkaDocumentLoader(\n",
    "    bootstrap_servers='localhost:9092',\n",
    "    topic='my-topic',\n",
    "    group_id='my-group',\n",
    "    auto_offset_reset='earliest',\n",
    "    security_protocol='SSL',\n",
    "    ssl_cafile='/path/to/ca.pem',\n",
    "    ssl_certfile='/path/to/service.cert',\n",
    "    ssl_keyfile='/path/to/service.key'\n",
    ")\n",
    "\n",
    "try:\n",
    "    documents = kafka_loader.load()\n",
    "    for doc in documents:\n",
    "        print(doc)\n",
    "except KafkaException as e:\n",
    "    print(f\"Kafka exception occurred: {e}\")\n",
    "finally:\n",
    "    kafka_loader.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Using and Integrating the Confluent Cloud with Langchain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.kafka import KafkaDocumentLoader\n",
    "\n",
    "# Confluent Cloud\n",
    "kafka_loader = KafkaDocumentLoader(\n",
    "    bootstrap_servers='pkc-abc123.us-west-2.aws.confluent.cloud:9092',\n",
    "    topic='my-topic',\n",
    "    group_id='my-group',\n",
    "    security_protocol='SASL_SSL',\n",
    "    sasl_mechanism='PLAIN',\n",
    "    sasl_username='<confluent-cloud-api-key>',\n",
    "    sasl_password='<confluent-cloud-api-secret>'\n",
    ")\n",
    "\n",
    "documents = kafka_loader.load()\n",
    "for doc in documents:\n",
    "    print(doc)\n",
    "\n",
    "kafka_loader.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-community-ifp_au_i-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
