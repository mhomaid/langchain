{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KafkaLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import KafkaDocumentLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kafka Producer in Langchain Integration with Kafka\n",
    "In the Langchain integration with Kafka, a Kafka Producer is used to send messages to a Kafka topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer\n",
    "import json\n",
    "\n",
    "# Kafka broker configuration\n",
    "broker_config = {\n",
    "    'bootstrap.servers': 'localhost:9092',\n",
    "    'client.id': 'my-producer',\n",
    "    'security.protocol': 'PLAINTEXT'\n",
    "}\n",
    "\n",
    "# broker_config = {\n",
    "#     'bootstrap.servers': 'broker:29092,broker2:29092,broker3:29092',\n",
    "#     'client.id': 'my-producer',\n",
    "#     'security.protocol': 'PLAINTEXT'\n",
    "# }\n",
    "\n",
    "# Create a Kafka producer instance\n",
    "producer = Producer(broker_config)\n",
    "\n",
    "# Callback function to handle delivery reports\n",
    "def delivery_report(err, msg):\n",
    "    if err is not None:\n",
    "        print(f'Message delivery failed: {err}')\n",
    "    else:\n",
    "        print(f'Message delivered to {msg.topic()} [{msg.partition()}]')\n",
    "\n",
    "# Test data\n",
    "data = [\n",
    "    {'name': 'John', 'age': 30},\n",
    "    {'name': 'Alice', 'age': 25},\n",
    "    {'name': 'Bob', 'age': 35}\n",
    "]\n",
    "\n",
    "# Send messages to Kafka\n",
    "for item in data:\n",
    "    message = json.dumps(item)\n",
    "    producer.produce('Langchain_test_topic', value=message.encode('utf-8'), callback=delivery_report)\n",
    "\n",
    "# Flush the producer to ensure all messages are sent\n",
    "producer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Using and Integrating the Apache Kafka Loader with Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from typing import Any, Callable, Iterator, Mapping, Optional\n",
    "from confluent_kafka import Consumer, KafkaException, KafkaError\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import KafkaDocumentLoader\n",
    "\n",
    "# Define a record handler function\n",
    "def record_handler(record: Any, id: Optional[str]) -> Document:\n",
    "    return Document(page_content=record.value().decode('utf-8'), metadata={'offset': record.offset(), 'timestamp': record.timestamp()})\n",
    "\n",
    "# Initialize KafkaDocumentLoader\n",
    "kafka_loader = KafkaDocumentLoader(\n",
    "    bootstrap_servers='localhost:9092',\n",
    "    topic='test_topic',\n",
    "    group_id='test_group',\n",
    "    auto_offset_reset='earliest',\n",
    "    record_handler=record_handler\n",
    ")\n",
    "\n",
    "# Load documents\n",
    "documents = kafka_loader.load()\n",
    "\n",
    "# Print the first document\n",
    "print(documents[0])\n",
    "\n",
    "# Close the loader\n",
    "kafka_loader.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-community-ifp_au_i-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
